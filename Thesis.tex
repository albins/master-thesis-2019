%
% Template for Doctoral Theses at Uppsala
% University. The template is based on
% the layout and typography used for
% dissertations in the Acta Universitatis
% Upsaliensis series
% Ver 5.2 - 2012-08-08
% Latest version available at:
%   http://ub.uu.se/thesistemplate
%
% Support: Wolmar Nyberg Akerstrom
% Thesis Production
% Uppsala University Library
% avhandling@ub.uu.se
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\documentclass{UUThesisTemplate}
\documentclass[11pt,a4paper,twoside,openany]{report}

\author{Albin Stjerna}
\date{\today}

% Package to determine wether XeTeX is used
\usepackage{ifxetex}

\ifxetex
	% XeTeX specific packages and settings
	% Language, diacritics and hyphenation
        \usepackage[babelshorthands]{polyglossia}
        \usepackage{xunicode}
	\setmainlanguage{english}
	%\setotherlanguages{swedish}

	% Font settings
	\setmainfont{Baskerville}
  %\setromanfont{Baskerville}
	\setsansfont{Helvetica Neue}
	%\setmonofont{Source Code Pro} % only minted!
\else
	% Plain LaTeX specific packages and settings
	% Language, diacritics and hyphenation
    % Use English and Swedish languages.
	\usepackage[british]{babel}

	% Font settings
	\usepackage{type1cm}
	\usepackage[latin1]{inputenc}
	\usepackage[T1]{fontenc}
	\usepackage{mathptmx}

	% Enable scaling of images on import
	\usepackage{graphicx}
\fi

\usepackage{listings}
\usepackage{chngcntr}
\usepackage{chngcntr}
\usepackage{fancyvrb}
\usepackage{multicol}
\usepackage[font={small,it}]{caption}

% Tables
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{longtable}
\usepackage{lipsum}
\usepackage{sectsty}
\usepackage{amsmath}
\usepackage{amssymb}

%\usepackage[lining]{sourcecodepro}
\allsectionsfont{\normalfont\sffamily\bfseries}

%\clubpenalty 4000
%\widowpenalty 4000

% Document links and bookmarks
\usepackage{url}

\usepackage[xetex, colorlinks=true,
            linkcolor=blue, citecolor=blue,
            urlcolor=blue,breaklinks]{hyperref}
%\def\UrlBreaks{\do\/\do-}
%\usepackage{breakurl}
            
\usepackage[
    backend=biber,
    natbib=true,
    style=ieee,
    sorting=none,
    %block=ragged,
    backref=true]{biblatex}
    \bibliography{bibliography.bib}


% Numbering of headings down to the subsection level
%\numberingdepth{subsection}

% Including headings down to the subsection level in contents
%\contentsdepth{subsection}

\setlength{\columnsep}{0.2cm}
\usepackage{pdfpages}
\usepackage{mathtools}
\usepackage{varioref}
\usepackage{nowidow}
%\usepackage{cleveref}
\usepackage[toc,page]{appendix}
\newcommand{\fixme}[1] {{\color{red}#1}}
\newcommand{\notmine}[0] {$^\dagger$}
\usepackage{microtype}
\usepackage[newfloat]{minted}
\usepackage{caption}

\newenvironment{sourcecode}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Listing}
\usepackage{csquotes}
\usemintedstyle{xcode}
\setminted{fontsize=\footnotesize}

\setnowidow[5]
\setnoclub[3]

\newcommand{\InRust}[1]{\mintinline{rust}{#1}}
\newcommand{\InDatalog}[1]{\mintinline{prolog}{#1}}
\newcommand{\expression}[1]{\boxed{#1}}

\newcommand{\RustBlock}[3]{
  \begin{sourcecode}
    \captionof{listing}{#2}
    \label{code:#1}
\begin{minted}{rust}
#3
\end{minted}
  \end{sourcecode}}

% Uncomment to use a custom abstract dummy text
%\abstractdummy{
% }

\usepackage{xparse}
%
\DeclarePairedDelimiterX{\Set}[1]{\{}{\}}{\setargs{#1}}
\NewDocumentCommand{\setargs}{>{\SplitArgument{1}{;}}m}
{\setargsaux#1}
\NewDocumentCommand{\setargsaux}{mm}
{\IfNoValueTF{#2}{#1} {#1\,\delimsize|\,\mathopen{}#2}}%{#1\:;\:#2}

\newcommand{\ntyperule}[2]{\begin{array}{c}#1\\\hline\raisebox{1pt}{\strut}#2\end{array}}
\newcommand{\Loan}[0]{l}

% Relations
\DeclareMathOperator{\Live}{Live}
\DeclareMathOperator{\Invalidated}{Invalidated}
\DeclareMathOperator{\MayBeInitialised}{MayBeInitialised}
\DeclareMathOperator{\Error}{Error}

\title{Modelling Rust's Reference Ownership Analysis Declaratively in Datalog}

\begin{document}
% Sync the counters:
\counterwithin{listing}{section}
\counterwithin{figure}{section}
\counterwithin{table}{section}
\counterwithin{equation}{section}

% %\frontmatter*
%     % Creates the front matter (title page(s), abstract, list of papers)
%     % for either a Comprehensive Summary or a Monograph.
%     % Authors of Comprehensive Summaries use this front matter
%     %\frontmatterCS
%     % Monograph authors use this front matter
%     %\frontmatterMonograph

    % Environment used to create a list of papers
    % \begin{listofpapers}
    % 	\item A Paper Discussed in this Thesis \label{apaperlabel}
    % \end{listofpapers}

\maketitle

\section*{Abstract}
Polonius is a reformulation of Rust's signature borrow check in Datalog.
  The borrow check is a static may-point-to analysis, used for alias control of
  references and to ensure affine types of potentially shared memory. Polonius
  extends the previous borrow check to a full flow-sensitive analysis on Rust's
  Mid-level Intermediate Representation, eventually allowing a number of
  desirable sound but currently disallowed patterns of coding to be accepted by
  the compiler. This thesis describes the current, partial implementation of
  Polonius, including the addition of (partial) initialisation and (full)
  liveness tracking contributed as part of the work for the thesis, ties it to
  the Oxide formal type system, and describes an exploratory study of input data
  for Polonius generated by analysing circa circa 20~000 popular publicly
  available Git repositories found on GitHub and the Crates.io Rust package
  index. Some central findings from the study are that deallocations are
  uncommon relative to other variable uses, and that the full flow-sensitive
  analysis is typically seldom needed. Indeed, surprisingly many functions
  (circa 64\%) actually do not create any references at all, and therefore does
  not need (most of) the Polonius analysis. Another conclusion from the study is
  that control-flow graph edge count and number of variables in the function
  under analysis seems to have the highest correlation to longer runtimes,
  and would therefore be useful proxies for the difficulty of an input.


\begingroup
        % To adjust the indentation in your table of contents, uncomment and enter the widest numbers for each level
        %  E.g.  \settocnumwidth{widest chapter number}{widest section number}{widest subsection number}...{...}
       %  \settocnumwidth{5}{4}{5}{3}{3}{3}
  \tableofcontents
  \listoffigures
  \listoftables
\endgroup
  
%\section*{Acknowledgements}

\chapter{Introduction}
%\epigraph{\fixme{short quote}}
%\mainmatter{}
% what are the contributions made?
% why?

Rust is a young systems programming language originally developed at Mozilla
Research~\cite{matsakis_rust_2014}. Its stated intention is to combine
high-level programming language features like automatic memory management and
strong safety guarantees with predictable performance and pay-as-you-go
abstractions in systems languages like C++. Particular attention is given to
guarantees of safety and against data races in concurrent programs.

One of its core features is the memory ownership model, which enables
compile-time safety guarantees against data races, unsafe pointer dereferencing,
and runtime-free automatic memory management.

This report describes the implementation of an experimental next-generation
memory safety checker for Rust called Polonius in an embedded Datalog engine. In
practice, the full analysis encompasses a variable liveness analysis,
initialisation and deinitialisation tracking (mostly implemented as part of the
work on this thesis), and may-reference analysis for validation of Rust's memory
safety guarantees and alias control.

Finally, the report investigates Polonius inputs generated from Rust code found
in ca 20~000 popular publicly available Git repositories found on Crates.io and
GitHub. The analysis evaluates the viability of hybrid modes of analysis where a
simpler and faster analysis is performed before engaging the full flow-sensitive
analysis, and studies what a typical input for the borrow check might look like
in practice.

The contributions made within the scope of the thesis project specifically
includes the implementation of liveness and initialisation calculations
(Sections~\ref{sec:var-livenes} and~\ref{sec:var-initalisation} respectively).
Finally, the report also evaluates the runtime performance of the system,
suggesting potential optimisations in Section~\ref{sec:optim-borr-check}, and
performs a field study of the shape of input data in
Section~\ref{sec:field-study-borrow}. The core rules of Polonius for the
provenance variable constraints were already written when the project started.
They are still described in Section~\ref{sec:loan-constr-prop} for completeness.
For clarity, sections detailing components not developed as part of this thesis
are marked with~(\notmine{}).

\chapter{Background}
Whenever a reference to a resource is created in Rust, its borrowing rules
described in Section~\ref{sec:borrowing-rules} must be respected for as long as
the reference is alive, including across function
calls~\cite{nichols_rust_nodate}. In order to enforce these rules, the Rust
language treats the scope of a reference, conventionally called its lifetime, as
part of its type, and also provides facilities for the programmer to name and
reason about them as they would any other type.

{\sloppy
Since its release, the Rust compiler has been extended through proposal RFC~2094
to add support for so-called non-lexical lifetimes (NLLs), allowing the compiler
to calculate lifetimes of references based on the control-flow graph rather than
the lexical scopes of variables~\cite{noauthor_rfc_2019}. During the spring of
2018, Nicholas Matsakis began experimenting with a new formulation of the borrow
checker, called Polonius, using rules written in
Datalog~\cite{matsakis_alias-based_2018}. The intention was to use Datalog to
allow for a more advanced, flow-sensitive analysis while also allowing for
better compile-time performance through the advances done centrally to the
fixpoint solving provided by the Datalog engine~\cite{datafrog}. Conceptually,
this reformulation also significantly alters the previous formulation of the
borrow check in terms of lifetimes, now centering it around the concept of the
loans giving rise to references.}

\section{Previous Research}
Datalog, and other types of logic programming has been previously employed for
program analysis, in particular pointer analyses such as may-point-to and
must-point-to analysis, both similar to what is described in this report in that
they require fix-point solving and graph traversal, often with a context
sensitive analysis (i.e. respecting function boundaries) like the
one described here~\cite{Dawson:1996:PPA:231379.231399,
  Berndl:2003:PAU:780822.781144, hajiyev_codequest:_2005,
  Whaley:2004:CCP:996893.996859, lam_context-sensitive_2005,
  Benton:2007:ISD:1273920.1273923, Hardekopf:2007:AGF:1250734.1250767,
  Smaragdakis:2011:PYC:1926385.1926390, smaragdakis_using_2010,
  balatsouras_datalog_2017, Madsen:2016:DFD:2908080.2908096,
  Eichberg:2008:DCC:1368088.1368142}. These systems employ a wide variety of
solver technologies and storage back-ends for fact storage, from Binary
Decision Diagrams (BDDs) to explicit tuple storage, as used in this study. Some
of them, like \textsc{Flix}, also extends Datalog specifically for static
program analysis~\cite{Madsen:2016:DFD:2908080.2908096}.

In addition to being context-sensitive, Rust's borrow checker is also
flow-sensitive (i.e. performs analysis for each program point), like the system
described by \citeauthor*{Hardekopf:2009:SFP:1480881.1480911}, and whose form is
very similar to the analysis performed in practice by
Polonius~\cite{Hardekopf:2009:SFP:1480881.1480911}.

A \citeyear{scholz_fast_2016}~study uses the Souffl{\'e} system, which
synthesizes performant C++ code from the Datalog specifications, similar to how
Datafrog embeds a minimal solver as a Rust library, to show promising
performance for analysis of large programs~\cite{scholz_fast_2016}. The
\textsc{Doop} system, developed by \citeauthor*{smaragdakis_using_2010}, also
shows that explicit tuple storage sometimes vastly outperforms BDDs in terms of
execution time~\cite{smaragdakis_using_2010}, as do sparse
bitmaps~\cite{Hardekopf:2007:AGF:1250734.1250767}.

Formally, the semantics of Rust's lifetime rules have been captured in the
language Oxide, described by \citeauthor*{weiss_oxide:_2019} in a draft paper
which describes a minimal Rust-like language called Oxide along with its type
system~\cite{weiss_oxide:_2019}. Oxide is notable in that it shares Polonius'
view of variables as sets of possible points in the code that would give rise to
the reference (``loans'' of the variable). The relationship between Oxide and
Polonius is discussed further in Section~\ref{sec:type-system}.

\section{The Borrowing Rules}\label{sec:borrowing-rules}

Conceptually, the borrow check verifies that Rust's ownership rules of shared
memory are respected. Memory is owned by the scope (typically a function, block,
or data structure) that has allocated it, and will be deallocated upon leaving
the scope of the owner. Memory can also dynamically change owners through a
move. For example, the constructor of a data structure can capture its arguments
and store them in the returned data structure, thus moving the memory without
performing a reallocation. The borrow check verifies that each memory access is
(definitely) owned (and initialised) at the point of the control-flow of each
access. It also verifies that accesses to shared memory through loans respect
the terms of that loan. A shared reference cannot be mutated, and must be
guaranteed to be free from use-after-frees.

This section will demonstrate the rules enforced by the borrow check. Most of
these examples are taken directly or slightly modified from
\citeauthor*{weiss_oxide:_2019}~\cite{weiss_oxide:_2019}.

\begin{description}  
\item[Variables must be provably initialised before use] Whenever a variable is
  used, it must be unconditionally initialised:
  \begin{minted}{rust}
     let x: u32;
     let y = x + 1; // ERROR: x is not initialised
  \end{minted}
\item[A move deinitialises a variable] Whenever ownership of a variable is
  passed on (\emph{moved} in Rust parlance), e.g. by a method call or use in an
  assignment, the variable becomes deinitialised:
  \begin{minted}{rust}
    struct Point(u32, u32);
    
    let mut pt = Point(6, 9);
    let x = pt;
    let y = pt; // ERROR: pt was already moved to x
  \end{minted}
\item[There can be any number of shared references] A shared reference, also
  called a \textit{loan} of a \textit{borrowed} variable, is created with the
  \InRust{&} operator, and there can be any number of simultaneously live shared
  references to a variable:
  \begin{minted}{rust}
    struct Point(u32, u32);
    
    let mut pt = Point(6, 9);
    let x = &pt;
    let y = &pt; // This is fine
  \end{minted}
\item[There can only be one simultaneous live unique reference] Whenever a
  unique reference is created, with \InRust{&mut}, it must be unique:
  \begin{minted}{rust}
    struct Point(u32, u32);
    
    let mut pt = Point(6, 9);
    let x = &mut pt;
    let y = &mut pt; // ERROR: pt is already borrowed
    
    // code that uses x and y
  \end{minted}

  This error happens even if the first borrow is shared, but not if
  either \InRust{x} or \InRust{y} are dead (not used).
  
\item[A reference must not outlive its referent] A reference must go out of
  scope at the very latest at the same time as its referent, protecting against
  use-after-frees:
  \begin{minted}{rust}
    struct Point(u32, u32);
    
    let x = {
        let mut pt = Point(6, 9);
        &pt
    };
    
    let z = x.0; // ERROR: pt does not live long enough
  \end{minted}

  In this example, we try to set \InRust{x} to point to the variable \InRust{pt}
  inside of a block that has gone out of scope before \InRust{x} does.
\end{description}


It is worth pointing out that the move semantics, corresponding to affine types,
only applies to types that are not cheaply clonable, indicated by them
implementing the \InRust{Copy} trait. In that case, any move would instead
automatically become a copy, using value semantics rather than reference
semantics. This is why the examples above do not use simpler types like
integers, which are copyable and thus would not cause a move to happen.

\subsection{Variables, Places, and Paths}
\label{sec:vars-places-paths}

A notable detail of the borrow check is what is meant by a ``variable''. In
Rust, some data structures, such as \InRust{struct}s (complex data types,
corresponding to objects without methods), and tuples, are analysed at the
granularity of the individual components, which may have arbitrarily deep
nesting (known statically). This means that the following code, for example, is
sound, as the loans do not overlap:
\begin{minted}{rust}
struct Point(u32, u32);

let mut pt: Point = Point(6, 9);
let x = &mut pt.0;
let y = &mut pt.1;
// no error; our loans do not overlap!
\end{minted}

In our instance, the root variable \InRust{pt} contains the \emph{paths}
\InRust{pt.1} and \InRust{pt.2}. Such paths constitute a tree with its root in
the variable itself. Both the core borrow check and the initialisation tracking
that we will discuss reasons about variables on the path level. It is worth
pointing out that dynamic structures like vectors, as well as arrays, are not
analysed at this granularity, but are considered one single object.

In Rust compiler parlance, we say that a path points to a \emph{place},
corresponding literally to the place in memory holding its data.

Finally, we sometimes talk of a path having \emph{prefixes}, where a prefix is
anything above and including a ``leaf'' in the tree spanning all paths. For
example, the path \InRust{x.y} would have the prefixes \InRust{x} and
\InRust{x.y}. Prefixes will also come up in initialisation tracking, and in the
borrow check itself.

\section{Why a Reformulation?}
\label{sec:background:why}

Polonius' design is driven by shortcomings of the current borrow checker (NLL),
which does not have the same degree of flow-sensitivity as Polonius provides.
For this reason, NLL rejects certain desirable patterns of Rust that Polonius is
designed to accept, such as the code in Listing~\ref{lst:issue-51132}. Leaving
out the flow-sensitive analysis of NLL was motivated by performance reasons and
is one of the motivations for using Datalog, in addition to the intention of
having a clearer formulation in a data-oriented language.

\begin{sourcecode}
  \captionof{listing}[Motivating example for Polonius]{A motivating example for
    Polonius, rejected by the current borrow checker. The code is sound, as the
    loaned \InRust{event} is either returned out of the loop, or overwritten at
    the next iteration. Therefore, there are no overlapping mutable loans of
    \InRust{buffer}.\cite{issue-51132}}\label{lst:issue-51132}
\begin{minted}{rust}
fn next<'buf>(buffer: &'buf mut String) -> &'buf str {
    loop {
        let event = parse(buffer);

        if true {
            return event;
        }
    }
}

fn parse<'buf>(_buffer: &'buf mut String) -> &'buf str {
    unimplemented!()
}
\end{minted}
\end{sourcecode}

\section{The Borrow Check in the Rust Compiler}
\label{sec:rust-specificts}

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/rustc-overview}
  \caption[The Rust Compilation Process]{An overview of the Borrow Check's place
    in the process of compiling Rust code, as described in the Rust Developer's
    Guide~\cite{rustc_developers_guide_nodate}.}
  \label{fig:rustc-overview}
\end{figure}

The logic of the borrow check as described in
Section~\ref{sec:reference-provenance} is calculated at the level of an
intermediate representation of Rust called the Mid-Level Intermediate
Representation (MIR), corresponding to the basic blocks of program control flow.
Rust is lowered to MIR after regular type checking and after a series of earlier
transformations, as seen in Figure~\ref{fig:rustc-overview}. The Polonius
analysis is executed at the function level, checking a function at a time.

The input data to Polonius is generated in the Rust compiler by analysing this
intermediate representation. This means that we can safely assume to be working
with simple variable-value assignment expressions, of the type \InRust{_1 = _2},
as opposed to complex expressions involving multiple variables on the right-hand
side.

\begin{figure}
  \includegraphics[width=0.65\linewidth]{Graphs/mir-example}
  \caption[MIR of a Small Rust Program With
  Function Call]{A graph rendering of the \InRust{main()} function from the Rust
    program in Listing~\ref{lst:mir-example-input}, illustrating branching
    (block 0), and a function call (5). Note the \texttt{unwind}~arm of
    block~5's terminator (last line), which will be followed if the function
    call panics, that is if something goes wrong during the call.}
  \label{fig:mir-example}
\end{figure}

The MIR consists of basic blocks in the traditional compilers sense, each
containing a set of statements and usually ending with a \emph{terminator}, an
expression providing a branching to other basic blocks~\cite{mir_rfc}. A
rendering of the MIR of the program in Listing~\ref{lst:mir-example-input} can
be seen in Figure~\ref{fig:mir-example}.

\begin{sourcecode}
  \captionof{listing}{A minimal Rust program featuring branching and a function
    call. The MIR~form of this program is shown in
    Figure~\ref{fig:mir-example}.}\label{lst:mir-example-input}
\begin{minted}{rust}
fn main() {
    let x = 17;
    let z = if x == 3 {
        92
    } else {
        x
    };

    do_something(z);
}
\end{minted}
\end{sourcecode}

\section{From Lifetimes to Provenance Variables}
\label{sec:reference-provenance}

As the lifetime of its value is a part of a reference variable's type, it can be
referred to by name using the syntax \InRust{&'lifetime}. In the literature, the
terms ``region''~\cite{matsakis_alias-based_2018}, ``(named)
lifetime''~\nocite{noauthor_rfc_2019}, and ``reference
provenance''~\cite{weiss_oxide:_2019} (provenance) are all employed. As the
section heading suggests, we will use the last one of them as we believe it best
captures the concept. Named provenances (such as \InRust{'lifetime} above) are
referred to as ``provenance variables''. For historical reasons, the name
``region'' sometimes occurs in Polonius' code as well. Moreover, during the work
on this thesis, a fourth term, ``origin'', was chosen to replace the term
``provenance variables'' used here. Additionally, a comprehensive re-naming of
all the terms used is also underway at the time of writing.

From a type system perspective, the provenance is part of the type of any
reference and corresponds to the borrow expressions (reference constructions)
that might have generated it in the Polonius formulation of the borrow check.
For example, if a reference \InRust{r} has the type \InRust{&'a Point},
\InRust{r} is only valid as long as the terms of the loans in \InRust{'a} are
upheld. Take for example the annotated code of
Listing~\ref{lst:multi-path-borrow}, where \InRust{p} would have the type
\InRust{&'a i32} where \InRust{a} is the set $\Set{L_0, L_1}$.

\begin{sourcecode}
  \captionof{listing}{An example of a multi-path loan where the value in
    \InRust{p} could point to either of the vector \InRust{x}'s values depending
    on the return value of the function \InRust{random()}. The code has been
    annotated with named provenance variables and would not compile
    as-is.}\label{lst:multi-path-borrow}
\begin{minted}{rust}
let x = vec![1, 2];

let p: &'a i32 = if random() {
  &x[0] // Loan L0
} else {
  &x[1] // Loan L1
};
\end{minted}
\end{sourcecode}

If a reference is used in an assignment like \InRust{let p: &'b i32 = &'a x},
the reference, \InRust{p}, cannot outlive the referenced value, \InRust{x}. More
formally the type of the right-hand side, \InRust{&'a i32}, must be a subtype of
the left-hand side's type; \InRust{&'a i32 <: &'b i32}. In practice, this
establishes that \InRust{'b} lives at most as long as \InRust{'a}, which means
that the subtyping rules for variables establishes a set membership constraint
between their provenance variables, as seen in Rule~\ref{eq:s-ref} of
Section~\ref{sec:type-system}, which gives a brief introduction to the reference
ownership analysis of Polonius from a type systems perspective.

Finally, when talking about the \emph{liveness} of a provenance variable $r$ at
some point in the control-flow graph $p$, we will mean that $r$ occurs in the
type of at least one variable which is live at $p$. This has the semantic
implication that any of the loans in $r$ might be dereferenced at control-flow
points reachable from $p$, and thus that the terms of the loans in $r$ must be
respected at that point. The possibility of a future access is not limited to
direct access of a variable, but also concerns uses in the custom deallocator of
a \InRust{struct} holding a reference. This scenario is further discussed in
Section~\ref{sec:deall-as-spec}.

\section{Reference Ownership as a Type System}\label{sec:type-system}

In this section, we will relate Polonius to the ongoing work of
\citeauthor*{weiss_oxide:_2019} on formalising the reference ownership rules of
Rust into the formally defined type system Oxide~\cite{weiss_oxide:_2019}. The
rules presented here are based on the 2019 draft version of the paper, and will
change substantially in the paper's final version.

The typing rules of this section are meant to be read top-to-bottom. They mean
that as long as the conditions above the horizontal bar holds, the conclusion
below it will hold; usually that an expression is sound with respect to the type
system (it type-checks). Most of the conventions used in the Oxide formulation
can be glossed over for our purposes here, but the most important ones are the
type environment~$\Gamma$, used to map places (roughly: variables) ($\pi,
\pi_1$, and so on) to their types ($\tau, \tau_1$, etc). As reference types
contain provenance variables ($\rho$), this type environment is stateful, in
that for example typing a reference-constructing expression would modify the
typing environment to add a new loan.

Judgments on the form~$\Gamma \vdash_{\omega} \pi \: : \: \tau$ mean that ``in
the environment~$\Gamma$, it is safe to use the variable~$\pi$ (of type~$\tau$)
$\omega$-ly'' \cite{weiss_oxide:_2019}. In other words, if $\omega$~is
\emph{unique}, it means that there are no live loans of any paths
overlapping~$\pi$, and of $\omega$~is \emph{shared} that there are no
overlapping loans in the provenance part of $\tau$. The full type system handles
degradation of these types of references, etc, but would be far beyond the scope
of our comparison here.

At the heart of the type system lies the flow-sensitive typing judgments seen in
Rules~\ref{eq:t-move} and~\ref{eq:t-borrow}, both taken from
\citeauthor*{weiss_oxide:_2019}'s paper (Figure~1). The first
rule~\eqref{eq:t-move} shows that for a given environment~$\Gamma$, a move of a
given variable~$\pi$ (occurring if $\pi$ cannot be copied, which is what the
right prerequisite says) is only valid if~$\pi$ is uniquely usable (that is, is
not shared) (left prerequisite) in $\Gamma$. The typing itself removes $\pi$
from the $\Gamma$, effectively barring it from future use as it has no type
(conclusion). This corresponds to the initialisation tracking of
Section~\ref{sec:var-initalisation}, as well as part of the invalidation logic
of Polonius.

\begin{equation}\label{eq:t-move}
  \ntyperule{
    \Gamma \vdash_{\text{mut}} \pi : \tau^s \:\:\:\:
    \text{noncopyable } \tau^s}
  {
    \Sigma ; \Delta ; \Gamma \vdash \expression{\pi} : \tau^s \Rightarrow \Gamma - \pi
  }
\end{equation}

The second rule, Rule~\eqref{eq:t-borrow}, states that we may create an
$\omega$-reference to any variable $\pi$ of type $\tau$ where $\omega$-use is
safe, and produce a reference of equal $\omega$~access to that variable of the
type ``reference to a value of type,~$\tau$, with its provenance variable being
the set containing only that loan, denoted $^{\omega}\pi$''. This corresponds to
the input fact \InDatalog{borrow_region}, described in
Section~\ref{sec:input-facts}, and follows the intuition that if we create a
reference, that reference is \emph{known} to point to whatever we borrowed to
create the reference.

\begin{equation}\label{eq:t-borrow}
  \ntyperule{
    \Gamma \vdash_{\omega} \pi : \tau}
  {
    \Sigma ; \Delta ; \Gamma \vdash \expression{\&\omega \pi} : \& \left \{ ^{\omega}\pi\right \} \omega \tau \Rightarrow \Gamma
  }
\end{equation}

Rules~\eqref{eq:t-move} and~\eqref{eq:t-borrow} constitute base cases for the
ownership system, showing how variables get removed from the environment, and
how provenance variables in reference types are created. In order to describe
the full analysis, we need to also consider how these relations extend across
program execution through sequencing or branching, of which the latter
introduces the approximate aspect of provenances. Finally, we will also describe
how provenance variables come into relation with each other through type
unification and subtyping.

Since the borrow check is performed on the MIR, Polonius does not handle
branchings in the normal sense. Therefore, the sequencing and branching rules of
Oxide only translate analogously. As in Oxide, the type environment of the MIR
is threaded through the typing of each expression, such that the sequence of
expressions~$\expression{e_1; e_2}$ would first type-check~$e_1$ and then~$e_2$
in the resulting environment after type-checking $e_1$. To capture this, we will
use the name~$\Gamma_p$ to refer to the type-environment mapping places to their
types just before evaluating an arbitrary point~$p$ of the~CFG.

In Oxide, the typing rules for branch expressions uses a type unification of the
value of the \InRust{if} expression such that its value unifies (that is,
merges) the provenance variables of the environments in both branches. The MIR
produced by such a branching would instead have a loop starting at the head of
the \InRust{if} expression and ending with an assignment to the same variable in
each branch before finally joining in a basic block where the assigned variable
now could have come from either arm, as in Figure~\ref{fig:mir-example} but with
references instead of regular values being assigned. Hence branching introduces
the first source of imprecision into the provenance variables.

How, then, does this type unification work for references? The rule,
\textsc{T-Ref}, Rule~\eqref{eq:u-ref}, tells us first that the two types
$\tau_1, \tau_2$ that we want to unify must in turn unify into a single type
$\tau$, which of less interest to us; in principle it means that whatever the
reference points to has compatible types. The conclusion of the rule is what is
of interest here. It says that these two references' provenance variables must
unify into the combined provenance $\rho$. Moreover, the access types of these
references must be compatible; they must have the same use-type $\omega$
(meaning that we cannot use a non-unique reference as a unique one). In
practice, this unification rule is what introduces the imprecision of this
analysis on branchings, and would correspond to the propagation of relations
across CFG edges in Polonius.

\begin{equation}\label{eq:u-ref}
  \ntyperule{
    \tau_1 \sim \tau_2 \Rightarrow \tau \:\:\:\:\: \rho_1 \cup \rho_2 = \rho}
  {
    \&\rho_1 \omega \tau_1 \sim \& \rho_2  \omega \tau_2 \Rightarrow \&\rho \omega \tau
  }
\end{equation}

Finally, provenance variables comes into relation with each other during
assignments and variable definitions. An assignment would have the form
\InRust{x = y} and would give the already-defined variable~\InRust{x} the value
of \InRust{y}. If \InRust{y} is not \InRust{Copy}, it would be moved to
\InRust{x} and be deinitialised. A definition would take the form \InRust{let x
  = y}, and would introduce a new variable \InRust{x} into the scope. The typing
judgments for both kinds of statements in Oxide are complex, and we will
therefore only gloss over them here.

Simply put, each assignment allows for different types on each side of the
assignment, as long as the types unify, as seen in Rule~\eqref{eq:t-assignment}
(Oxide's \textsc{T-Assign} rule), which says two things of interest to us.
First, an assignment is only possible if the left-hand side of the expression
can be unified with the right-hand side (the prerequisite), and second that
assignment will remove the previous mapping of $\pi_1$ in $\Gamma$ and replace
it with the new expression. The call to the meta-function \texttt{places-typ} is
used to expand $\pi$ into all its references and perform the assignment. This
would correspond to the \InDatalog{killed} relation used in Polonius, where an
old loan is removed from the environment whenever one of its prefixes is
assigned. Additionally, Polonius would also have assignment and initialisation
inputs for the liveness and initialisation tracking respectively, but those are
beside the point of this discussion.

\begin{equation}\label{eq:t-assignment}
  \ntyperule{
    \Gamma \vdash_{\texttt{uniq}} \pi : \tau_o \:\:\:\:\:
    \tau_o \sim \tau_u \Rightarrow \tau_n \\
    \Sigma ; \Delta ; \Gamma \vdash \expression{e} : \tau_u \Rightarrow \Gamma_1 \\
    \texttt{places-typ}(\pi, \tau_u) = \overline{\pi : \tau} \\
  }
  {
    \Sigma ; \Delta ; \Gamma \vdash \expression{\pi = e} \: : \: \texttt{unit} \Rightarrow \Gamma_1 - \pi_1, \overline{\pi : \tau}
  }
\end{equation}

Finally, variable binding is what introduces relations between provenance
variables, which is another source of imprecision in the analysis. Glossing over
the complexities of the typing rule for \InRust{let}~expressions (Oxide's
\textsc{T-Let} or~\eqref{eq:t-let}), we can see that a variable definition would
update the variable's type in the environment and, the crucial part, imply a
subtyping relationship between the left-hand side of the expression and the
right-hand side, the $\Sigma \vdash \tau_1 ^s <: \tau_a^s \leadsto \delta$
prerequisite, which is then used in the new scope created by the binding. This
subtyping rule, Rule~\eqref{eq:s-ref}, is what actually introduces the
relationship between provenance variables of references.

\begin{equation}\label{eq:t-let}
  \ntyperule{
    \Sigma ; \Delta ; \Gamma \vdash \expression{e_1} \: : \: \tau_1^s \Rightarrow \Gamma_1
    \:\:\: \Sigma \vdash \tau_1 ^s <: \tau_a^s \leadsto \delta \\
    \texttt{places-typ}(\mathtt{x}, \delta(\tau^s_a)) = \overline{\pi : \tau} \\
    \Sigma ; \Delta ; \Gamma, \overline{\pi : \tau} \vdash \delta(e_2) : \tau_2^s \Rightarrow \Gamma_2
  }
  {\Sigma ; \Delta ; \Gamma \vdash \expression{\texttt{let } \mathtt{x} = \pi_2} \: : \: \tau_2^s \Rightarrow \Gamma_2 - \mathtt{x}}
\end{equation}

The subtyping rule for references, Rule~\eqref{eq:s-ref}, says that a reference
type~$\tau_1$ is a subtype of a (reference) type~$\tau_2$ if the things they
refer to are also subtypes (with the substitution~$\delta$), and, crucially
here, if $\tau_1$'s provenance variable is a subset of $\tau_2$'s. The meaning
here is that $\tau_1$ can only act as a $\tau_2$ if it points to something
compatible (the rightmost prerequisite), if the uses are compatible (the middle
prerequisite), and if the $\tau_1$ does not require any loans except the ones in
$\tau_1$, the super-type. The intuition for this is that if we are to use
$\tau_1$ as a $\tau_2$, the conditions of that loan must not include conditions
(notably, liveness of the value at the other end of the reference) beyond what
$\tau_2$ promises. In Polonius, this is represented by the \InDatalog{outlives}
fact, which is the major source of constraints on loans.

\begin{equation}\label{eq:s-ref}
  \ntyperule{
    \rho_1 \subseteq \rho_2 \:\:\:\:\:\:\:\:
    \omega_1 \leq \omega_2 \:\:\:\:\:\:\:\:
    \Sigma \vdash \tau_1 <: \tau_2 \leadsto \delta
  }
  {
    \Sigma \vdash \&\rho_1 \omega_1 \tau_1 <: \& \rho_2 \omega_2 \tau_2 \leadsto \delta
  }
\end{equation}

\section{Deallocation As a Special Case of Variable Use}
\label{sec:deall-as-spec}
When Rust's variables go out of scope, they are implicitly deallocated, or
dropped in Rust parlance. Explicit deallocation is also possible by calling the
function \InRust{drop()}, which takes ownership of a variable (that is,
deinitialises it) and performs deallocation, or, for complex objects, calls the
\InRust{drop()} method. For some types such as integers, deallocation is not
necessary and the compiler generates no actual \InRust{drop()}:s in the MIR.
However, the process of inferring this, called drop elision, happens after
Polonius is invoked, and therefore Polonius needs to calculate which
\InRust{drop()} statements would be no-ops.

Rust provides a default deallocator for data structures, but it can be
overridden. This has repercussions on liveness calculations, because while the
default deallocator for an object never needs to access its fields except to
deallocate them, a custom deallocator might access any of them in arbitrary
ways. This means that any conditions of a loan that resulted in a reference $r$
stored in a \InRust{struct} $s$ instance $a$ must only be respected as far as
\InRust{a.drop()} is concerned if $s$ implements a custom deallocator. Otherwise
the loan of $r$ may be safely violated, as the default deallocator never
dereferences $r$ and thus does not require $r$ to be valid. An illustration of
this can be seen in Listing~\ref{lst:drop-liveness}.

\begin{sourcecode}
  \captionof{listing}{The custom deallocator for \InRust{OwnDrop} enforces the
    loan giving the reference \InRust{data} until the struct is deallocated, but
    the loan in \InRust{DefaultDrop} is effectively dead as soon as it has no
    direct uses in the code and thus can be violated.}\label{lst:drop-liveness}
\begin{minted}{rust}
struct OwnDrop<'a> {
    data: &'a u32,
}

struct DefaultDrop<'a> {
    data: &'a u32,
}

impl<'a> Drop for OwnDrop<'a> {
    fn drop(&mut self) {
        // might access self.data
    }
}

fn main() {
    let mut x = 13;
    let a = OwnDrop { data: &x };

    let mut y = 12;
    let b = DefaultDrop { data: &y };
    
    let mutrefa = &mut x;
    // ERROR: the loan of x must be respected...
    
    // ...but the loan of y need not be!
    let mutref = &mut y;
    *mutref = 17;
    
    // all variables are implicitly dropped here
}
\end{minted}
\end{sourcecode}

\begin{figure}
  \includegraphics[width=0.65\linewidth]{Graphs/drop-main-mir}
  \caption[MIR of a Program Utilising a Custom Deallocator]{A graph rendering of
    the MIR produced from the \InRust{main()} function of
    Listing~\ref{lst:drop-liveness} illustrating a call to the custom
    deallocator of~\InRust{_2} that would cause it to be drop-live during the
    block. Take special note of the lack of calls to \InRust{drop(_6)}; as
    \InRust{DefaultDrop}, the \InRust{struct} stored in \InRust{_6}, uses the
    default deallocator and contains only a reference, deallocating it is a
    no-op. Some irrelevant details, such as hints about stack allocations and
    deallocations of intermediate variables, have been pruned.}
  \label{fig:mir-drop}
\end{figure}

Following the MIR translation of Listing~\ref{lst:drop-liveness} in
Figure~\ref{fig:mir-drop}, we see across the slightly confusing re-borrows used
to move the created references into the \InRust{struct}s that the only block of
the function ends with a call to \InRust{drop()} that would invoke the custom
deallocator. Here, the deallocator for \InRust{b}, our instance of
\InRust{DefaultDrop}, is never even called at all.

\section{Datafrog, a Datalog Embedded in Rust}
\label{sec:datalog}

Datalog is a derivative of the logic programming language Prolog, with the
desirable properties that any program terminates in polynomial time, and in some
variants also with the power to express all polynomial-time
computation~\cite{afrati_datalog_1995}. It describes fixpoint calculations over
logical relations as predicates, described as fixed input \emph{facts}, computed
\emph{relations}, or \emph{rules} describing how to populate the relations based
on facts or other relations. For example, defining a fact describing that an
individual is another individual's parent might look like
\InDatalog{parent(mary, john).}, while computing the \InDatalog{ancestor}
relation could then use the two rules, reflecting the fact that ancestry is
respectively either direct parenthood or transitive parenthood (example from the
Wikipedia article on Datalog~\cite{wiki:datalog}):
\begin{minted}{rust}
ancestor(X, Y) :- parent(X, Y).
ancestor(X, Y) :- parent(X, Z), ancestor(Z, Y).
\end{minted}

Datafrog~\cite{datafrog} is a minimalist Datalog implementation embedded in
Rust, providing an implementation of a worst-case optimal join algorithm as
described in~\cite{ngo_worst-case_2012}. The fact that Datafrog is embedded in
Rust means that standard Rust language abstractions are used to describe the
computation. Static facts are described as \InRust{Relation}s, while dynamic
\InRust{Variable}s are used to capture the results of computations, both of
which are essentially sets of tuples, in our case tuples of integers. Rules are
described using a join with either a \InRust{Variable} or a \InRust{Relation},
with an optimised join method used for joins with only one variable. Only
single-step joins on the first tuple element are possible, which means that more
complex rules must be written with intermediary variables, and manual indices
created whenever a relation must be joined on a variable which is not the first
in the tuple.

\begin{sourcecode}
  \captionof{listing}{The implementation of \InDatalog{var_live(V, P)} in
    Datafrog.}\label{lst:datafrog:var-live}
\begin{minted}{rust}
var_live_var.from_leapjoin(
    &var_live_var,
    (
        var_defined_rel.extend_anti(|&(v, _q)| v),
        cfg_edge_reverse_rel.extend_with(|&(_v, q)| q),
    ),
    |&(v, _q), &p| (v, p),
);
\end{minted}
\end{sourcecode}

As an example, the Datafrog code for \InDatalog{var_live(V, P)} of
Listing~\ref{lst:var-live} becomes the code in
Listing~\ref{lst:datafrog:var-live}, and the corresponding join used for the
first half of \InDatalog{region_live_at(R, P)} of
Listing~\ref{lst:region-live-at} can be seen in
Listing~\ref{lst:datafrog:region-live-at}.

\begin{sourcecode}
  \captionof{listing}{The first half of the implementation of
    \InDatalog{region_live_at(R, P)} in
    Datafrog.}\label{lst:datafrog:region-live-at}
\begin{minted}{rust}
region_live_at_var.from_join(
    &var_drop_live_var, 
    &var_drops_region_rel, 
    |_v, &p, &r| {
        ((r, p), ())
    });
\end{minted}
\end{sourcecode}

Joins in Datafrog are done using one of two methods on the variable that is to
be populated (e.g. in Listing~\ref{lst:datafrog:region-live-at}
\InRust{region_live_at_var}), a variable with tuples of the format \InRust{(Key,
  Val1)}. The first method, \InRust{from_join}, performs simple joins from
variables or relations into the (possibly different) target variable. Its
arguments, in order, are a \InRust{Variable} of type \InRust{(Key, Val2)}, and
either a second \InRust{Variable} or a \InRust{Relation} of type \InRust{(Key,
  Val3)}. The third and final argument is a combination function that takes each
result of joining the two non-target arguments, a tuple of type \InRust{(Key,
  Val2, Val3)}, and returns a tuple of format \InRust{Key, Val1} to be inserted
into the target variable.

In the example of Listing~\label{lst:datafrog:region-live-at}, the target
variable~\InRust{region_live_at_var} is populated by joining the
\InRust{Variable} \InRust{var_drop_live_var} to the \InRust{Relation}
\InRust{var_drops_region_rel}. Here, the combination function ignores the
variable, returning only the resulting provenance variable and CFG point. The
final result is stored in the first half of \InRust{region_live_at} with the
empty tuple as the second half. This is a work-around to enable joins with two
two-tuples.

For more complex joins where a single variable participates in the join and all
other arguments are static \InRust{Relation}s (such as is the case with the
variable~\InRust{var_live_var} of Listing~\ref{lst:datafrog:var-live}), there is
\InRust{from_leapjoin}. In this case, the input is the sole dynamic source
variable, a tuple of ``leapers'', and a combining function like the one in
\InRust{from_join}, but with the signature like the one above, mapping a matched
tuple from the join to the target of the join.

A leaper is created from a \InRust{Relation} of type \InRust{(Key, Value)} by
either applying the method \InRust{extend_with} or \InRust{extend_anti} for a
join or an anti-join respectively. Both of these functions then take a function
mapping tuples from the \InRust{Variable} to \InRust{Key}s in the
\InRust{Relation} being (anti-)joined. In the case of \InRust{extend_anti}, any
tuples matching \InRust{Key} are discarded.

In Listing~\ref{lst:datafrog:var-live}, we can see a leapjoin populating
\InRust{var_live_var} with tuples produced by joining the \InRust{Relation}s
representing \InRust{var_defined_rel} and the reversed CFG.

In this thesis, we will use the notation of Souffl{\'e}~\cite{scholz_fast_2016}
for all examples for clarity and brevity, even though the actual code was
written in Datafrog. In other words, starting from the next section, it would be
safe to forget you ever read this one.

\chapter{A Declarative Model of the Rust Borrow Check}
\label{cha:investigation}
% \epigraph{\fixme{short quote}}

\section{The Borrow Checker in Datalog}\label{sec:borr-check-datal}

An overview of Polonius can be seen in Figure~\ref{fig:polonius-overview}:
initialisation is calculated in order to calculate drop-liveness, which together
with regular use-liveness is used to determine the actual liveness of variables.
The liveness of variables is then used to determine the liveness of provenance
variables in their types, and is used throughout the calculations. Subset
relations between provenance variables are used to determine the set membership
of loans, and those are then combined with the liveness information in order to
determine which loans are live at which point of the program flow. Errors,
finally, are generated whenever a potentially violating operation happens to a
live loan (an observed tree falls in the woods, thus making a sound).

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/polonius-overview}
  \caption[Flowchart of the Polonius Inputs and Outputs]{An overview of how the
    inputs and intermediate steps of Polonius combine into the final output.
    Blue boxes represent facts and relations implemented during the work on this
    thesis. Relations are shown using boldface, and facts in regular font. The
    historical term ``region'' is used here instead of provenance variables to
    match the convention used in the actual code.}
  \label{fig:polonius-overview}
\end{figure}

\subsection{Input Facts}
\label{sec:input-facts}

The following short-hand names are used:
\begin{description}
\item[$R$] is a provenance variable, a set of loans.
\item[$L$] is a loan, that is a \InRust{&v} expression creating a reference
  to \InRust{v}.
\item[$P, Q$] are points in the control-flow graph of the function under analysis.
\item[$V$] is a variable.
\item[$M$] is a move path, that is a part of a variable that can be accessed
  and, more importantly, moved. This can be the name of a variable (e.g.
  \InRust{a}), or an access to a field of a data structure or one of a tuple's
  projections (e.g. \InRust{a.b}, or \InRust{a.1}).
\end{description}


\begin{description}
\item[\InDatalog{borrow_region(R, L, P)}] the provenance variable~$R$ may refer
  to data from loan $L$ starting at the point $P$ (this is usually the point
  \emph{after} the right-hand-side of a borrow expression).
  
\item[\InDatalog{universal_region(R)}] for each named/parametrised provenance
  variable~$R$ supplied to the function. $R$ is considered universally
  quantified, and therefore live in every point of the function.
  
\item[\InDatalog{cfg_edge(P, Q)}] whenever there is an edge~$P \rightarrow Q$ in
  the control flow graph.
    
\item[\InDatalog{killed(L, P)}] when some prefix of the path borrowed in $L$ is
  assigned at point~$P$, meaning that reference is overwritten.
    
\item[\InDatalog{outlives(R1, R2, P)}] when $R_1 \subseteq R_2$ must hold at
  point~$P$, a consequence of subtyping relationships as described in
  Rule~\eqref{eq:s-ref}. The term ``outlives'' has a historical origin in the
  previous terminology of lifetimes and the input will be renamed in future
  versions of Polonius.
    
\item[\InDatalog{invalidates(P, L)}] when the loan~$L$ is invalidated by some
  operation at point~$P$.
    
\item[\InDatalog{var_used(V, P)}] when the variable~$V$ is used for anything but
  a drop at point~$P$.
    
\item[\InDatalog{var_defined(V, P)}] when the variable~$V$ is assigned to
  (killed) at point~$P$.
  
\item[\InDatalog{var_drop_used(V, P)}] when the variable~$V$ is used in a drop
  at point~$P$.

\item[\InDatalog{var_uses_region(V, R)}] when the type of~$V$ includes the
  provenance~$R$.

\item[\InDatalog{var_drops_region(V, R)}] when the type of~$V$ includes the
  provenance~$R$, and~$V$ also implements a custom drop method which might need
  all of~$V$'s data, as discussed in Section~\ref{sec:deall-as-spec}. Notably,
  for the MIR in Listing~\ref{fig:mir-drop}, \InDatalog{var_drops_region(_2, R)}
  would be emitted to indicate that the \InRust{struct} stored in \InRust{_2}
  contains a reference with the provenance variable $R$ in its type, and that
  this reference could be accessed during the deallocation at this point, were
  it to happen.

\item[\InDatalog{child(M1, M2)}] when the move path $M_1$ is the child of $M_2$,
  That is, for example in the expression \InRust{x.y.z}, \InRust{x.y.z} is a
  child of \InRust{x.y} and \InRust{x}. In the implementation at the time of
  writing, \InDatalog{child} contained all descendants (children of children),
  but in future versions the intention is to just use direct relations and have
  Polonius infer the transitive closures.

\item[\InDatalog{path_belongs_to_var(M, V)}] if $M$ is the root path into $V$.

\item[\InDatalog{initialized_at(M, P)}] when the move path $M$ was initialized
  at point $P$, such as for example in the expression \InRust{x.y = 17}, which would
  initialise the path \InRust{x.y}. Note that the fact is emitted only for the
  specific path being initialised, and that the transitive initialisation of the
  prefix' children is implicit.

\item[\InDatalog{moved_out_at(M, P)}] when the move path $M$ was moved out
  (deinitialised) at point $P$. The same logic about implicit moves as for
  \InDatalog{initialzed_at} applies here.

\item[\InDatalog{path_accessed_at(M, P)}] when the move path $M$ was accessed at
  point $P$. This fact is not used in any of the current calculations, but is
  the final component needed to calculate erroneous accesses of (potentially)
  moved paths.
\end{description}

\subsection{Variable Initialisation}
\label{sec:var-initalisation}

The idea behind variable initialisation calculations is a fairly straightforward
transitive closure computation. Initialisation for a path propagates forwards
from an initialisation event across the CFG until the path is deinitialised. As
a consequence of this, initialisation tracking is imprecise (over-estimating)
upon branching; if one path to a node in the CFG has $v$ initialised and one
does not, $v$ is considered initialised for the purposes of this analysis.

For the purposes of this analysis, we mean by initialisation also partial
initialisation of a complex variable. Therefore, initialisation also propagates
upwards through the path tree, such that \InRust{x} is (partially) initialised
whenever \InRust{x.y} is. An expression like \InRust{move x} would, in this
example, only emit \InDatalog{moved_out_at(x, p)} as a starting fact. This means
that currently, initialisation tracking is imprecise with respect to parts of
the variable as well as across branchings, a strictly speaking unnecessary
imprecision. Future versions of Polonius will instead use a precise calculation
here, but for the purposes of determining drop-liveness in the next section
these calculations will suffice.

Finally, \InDatalog{path_belongs_to_var(P, V)} connects paths to their root
variables. It is worth noting here that this fact only needs to contain a
mapping of the root path to a variable, as initialisation always bubbles up
through the tree due to the imprecision mentioned above. The full Datalog code
is shown in Listing~\ref{lst:var-initialised}.

\begin{sourcecode}
  \captionof{listing}{The rules for computing possible partial variable
    initialisation. A path is trivially initialised where it is actually
    initialised. It is transitively initialised in all points reachable from a
    point where it is initialised, and where it has not been deinitialised
    (moved out). Initialisation propagates upwards in the move path tree, until
    it reaches the variable at the root of the path.}\label{lst:var-initialised}
\begin{minted}{prolog}
path_maybe_initialized_on_exit(Path, Point) :- 
    initialized_at(Path, Point).

path_maybe_initialized_on_exit(M, Q) :-
    path_maybe_initialized_on_exit(M, P),
    cfg_edge(P, Q),
    !moved_out_at(M, Q).

path_maybe_initialized_on_exit(Mother, P) :-
    path_maybe_initialized_on_exit(Daughter, P),
    child(Daughter, Mother).

var_maybe_initialized_on_exit(V, P) :-
    path_belongs_to_var(M, V),
    path_maybe_initialized_at(M, P).
\end{minted}
\end{sourcecode}

\subsection{Variable Liveness}
\label{sec:var-livenes}

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/liveness.pdf}
  \caption[MIR Fragment with Inputs and Outputs of the Liveness Analysis]{A
    graph representation of the the variable liveness calculation results, with
    relevant Polonius facts as they occur (a droplet symbolising
    \InDatalog{var_drop_used}, a wrench \InDatalog{var_used}, and a skull and
    crossbones symbolising \InDatalog{var_defined}). Variables are named by
    prefixing underscores, and edges annotated with the propagated live variable
    and its liveness type(s) (\textbf{D}rop or \textbf{U}se).}
  \label{fig:liveness-graph}
\end{figure}

The basic liveness of a variable (Listing~\ref{lst:var-live}) is computed
similarly to variable initialisation, except with variable uses instead of
initialisations, assignments instead of uses, and backwards across the CFG.
Specifically, the rule is as follows: if a variable~$v$ is live in some
point~$q$ and~$q$ is reachable from $p$ in the control-flow graph, then~$v$ is
live in~$p$ too unless it was overwritten. Like initialisation, it is also
imprecise with respect to branchings, as there is no way to know statically
which branch is taken.

\begin{sourcecode}
  \captionof{listing}{The rules for calculating use-liveness: a variable is
    use-live if it was used at a point $P$, or if it was live in $Q$, there is a
    transition $P\rightarrow{}Q$, and it was not defined (killed) in
    $P$.}\label{lst:var-live}
\begin{minted}{prolog}
var_live(V, P) :- var_used(V, P).

var_live(V, P) :-
    var_live(V, Q),
    cfg_edge(P, Q),
    !var_defined(V, P).
\end{minted}
\end{sourcecode}

Drop-liveness is calculated in a similar fashion to use-liveness, with the
exception that a deinitialised variable is never dropped, and therefore is not
considered drop-live. This is the reason for the computation of variables that
might be initialised in the previous section. The rules can be found in
Listing~\ref{lst:use-live}.

Note the use of the first rule, which is not transitive, to shift the point of
the initialisation from the input's mid-point index (which is where a
(de)initialisation would take effect) to the statement's starting-point. This is
because a drop-use would only happen if the \InRust{x} was initialised on
\textit{entry} to the instruction \InRust{drop(x)}.

An example of the output from this calculation can be seen in
Figure~\ref{fig:liveness-graph}.

\begin{sourcecode}
  \captionof{listing}{The rules for calculating drop-liveness: the rules are
    similar to those for to use-liveness (Listing~\ref{lst:var-live}), but
    propagation of liveness only happens if the variable being dropped may be
    initialised. Note that the rule for calculating initialisation on entry is
    not transitive!}\label{lst:use-live}
\begin{minted}{prolog}
var_maybe_initialized_on_entry(V, Q) :-
    var_maybe_initialized_on_exit(V, P),
    cfg_edge(P, Q).

var_drop_live(V, P) :-
    var_drop_used(V, P),
    var_maybe_initialzed_on_entry(V, P).

var_drop_live(V, P) :-
    var_drop_live(V, Q),
    cfg_edge(P, Q),
    !var_defined(V, P)
    var_maybe_initialized_on_exit(V, P).
\end{minted}
\end{sourcecode}

The two kinds of liveness are then used to calculate the reference liveness
relation (Listing~\ref{lst:region-live-at}), which serves as input for the rest
of the borrow checker. A given provenance variable~$R$ is live at some point~$p$
if it is in the type of a variable~$v$ which is either drop-live or use-live
at~$p$, with some notable caveats for drop-liveness (discussed in
Section~\ref{sec:deall-as-spec}) embedded in the \InDatalog{var_drops_region}
relation. In essence, even if $v$ is a \InRust{struct} containing a reference
with a provenance variable~$R$, this point would have
\InDatalog{var_drops_region(V, R)}, showing that the drop-use of $v$ would
require the liveness of the variable holding a reference with $R$ in its type.

\begin{sourcecode}
  \captionof{listing}{A provenance variable is live if it either belongs to a
    use-live variable, or if it might be dereferenced during the deallocation of
    a drop-live variable.}\label{lst:region-live-at}
\begin{minted}{prolog}
region_live_at(R, P) :-
    var_drop_live(V, P),
    var_drops_region(V, R).
        
region_live_at(R, P) :-
        var_live(V, P),
        var_uses_region(V, R).
\end{minted}
\end{sourcecode}

\subsection{Loan Constraint Propagation\notmine{}}\label{sec:loan-constr-prop}

The first relation used in Polonius is the \InDatalog{subset(R1, R2, P)}
relation, which states that~$R_1 \subseteq R_2$ for two provenance
variables~$R_1, R_2$ at point~$p$ in the CFG, and correspond to the constraints
generated during validation of expressions involving subtyping, as discussed in
Section~\ref{sec:type-system}. Initially, these have to hold at the points where
the constraints are generated by the Rust compiler, as seen by the input
parameter~\InDatalog{outlives}. The brief one-liner in
Listing~\ref{lst:subset-outlives} captures this fact, providing a ``base case''
for the computation. Additionally the mathematical fact that the subset relation
is transitive is captured in Listing~\ref{lst:subset-transitive}.

\begin{sourcecode}
  \captionof{listing}{Subset relations hold at the point where they are
    introduced.}\label{lst:subset-outlives}
\begin{minted}{prolog}
subset(R1, R2, P) :- outlives(R1, R2, P).
\end{minted}
\end{sourcecode}

\begin{sourcecode}
  \captionof{listing}{Subset relations are transitive.}\label{lst:subset-transitive}
\begin{minted}{prolog}
subset(R1, R3, P) :-
    subset(R1, R2, P),
    subset(R2, R3, P).
\end{minted}
\end{sourcecode}

Finally, Polonius needs logic to carry these subset relations across program
flow. However, as mentioned before, we are only interested in detecting
violations of loans that are actually live. Therefore, subset relation should be
propagated across an edge of the control-flow graph if and only if its
provenance variables are live, otherwise we are in a ``if a tree falls in the
woods'' situation where the conditions of the loans can be safely violated as
there is no live reference to be affected. Therefore, the rule for propagating
the subset constraint across a CFG~edge $P \rightarrow Q$ becomes the
formulation seen in Listing~\ref{lst:subset-propagation}, using the output of
the liveness calculations described in Section~\ref{sec:var-livenes}.

\begin{sourcecode}
  \captionof{listing}{Subset relations propagate across CFG~edges iff their
    provenance variables are live.}\label{lst:subset-propagation}
\begin{minted}{prolog}
subset(R1, R2, Q) :-
    subset(R1, R2, P),
    cfg_edge(P, Q),
    region_live_at(R1, Q),
    region_live_at(R2, Q).
\end{minted}
\end{sourcecode}

These rules describe how provenance variables relate to each other. The other
part of the logic describes which loans belong to which provenance variable. The
trivial base case is shown in Listing~\ref{lst:requires-borrow}, which just says
that each provenance variable~$R$ contains the loan~$L$ that created it at point
the point~$P$ where the borrow occurred.

\begin{sourcecode}
  \captionof{listing}{A provenance variable trivially contains
    (\InDatalog{require}s) the loan which introduced
    it.}\label{lst:requires-borrow}
\begin{minted}{prolog}
requires(R, L, P) :- borrow_region(R, L, P).
\end{minted}
\end{sourcecode}

Additionally, the \InDatalog{requires}~relation needs to be propagated together
with subset constraints; after all $R_1 \subseteq R_2$ implies that $R_2$ must
contain (\InDatalog{require}) all of $R_1$'s~loans. This is captured by the rule
in Listing~\ref{lst:requires-subset}.

\begin{sourcecode}
  \captionof{listing}{A subset relation between two provenance variables $R_1$,
    $R_2$ propagates the loans of $R1$ to $R2$.}\label{lst:requires-subset}
\begin{minted}{prolog}
requires(R2, L, P) :- 
  requires(R1, L, P), 
  subset(R1, R2, P).
\end{minted}
\end{sourcecode}

Finally, Polonius performs the flow-sensitive propagation of these membership
constraints across edges in the CFG. This is done using the rule in
Listing~\ref{lst:requires-edge}, where the requirements propagate across
CFG~edges for every loan~$L$ as long as the reference corresponding to~$L$ is
not overwritten (\InDatalog{killed}), and only for provenance variables that are
still live. This corresponds to the \textsc{T-Assignment} rule of Oxide, seen in
Rule~\eqref{eq:t-assignment}.

\begin{sourcecode}
  \captionof{listing}{Propagate loans across CFG edges for live provenance
    variables and loans whose references are not
    overwritten.}\label{lst:requires-edge}
\begin{minted}{prolog}
requires(R, L, Q) :-
  requires(R, L, P),
  !killed(L, P),
  cfg_edge(P, Q),
  region_live_at(R, Q).
\end{minted}
\end{sourcecode}


\subsubsection{Detecting Loan Violations}

The compiler produces a set of points in the CFG where a loan could possibly be
violated (e.g. by producing a reference to a value that already has a unique
reference) in \InDatalog{invalidates}. All that remains for Polonius is to
figure out which loans are live where (Listing~\ref{lst:loan-live}), and
determine if any of those points intersect with an invalidation of that loan
(Listing~\ref{lst:error-invalidates}).

\begin{sourcecode}
  \captionof{listing}{Loans are live when their provenance variables
    are.}\label{lst:loan-live}
\begin{minted}{prolog}
loan_live_at(L, P) :-
  region_live_at(R, P),
  requires(R, L, P).
\end{minted}
\end{sourcecode}

\begin{sourcecode}
  \captionof{listing}{It is an error to invalidate a live
    loan.}\label{lst:error-invalidates}
\begin{minted}{prolog}
error(P) :-
  invalidates(P, L),
  loan_live_at(L, P).
\end{minted}
\end{sourcecode}

\section{What is Missing from Polonius?}\label{sec:missing-features}

In addition to polish, comprehensive benchmarking, and performance
optimisations, all discussed later, there are three important features missing
in Polonius before it reaches parity with NLL, the current borrow checker.

\subsection{Detecting Access to Deinitialised Paths}
\label{sec:missing-features:move}

The current Polonius implementation only uses move data to derive conditional
initialisation of variables in order to determine if they would be deallocated.
However, the full borrow check would also calculate paths that \emph{may have
  been moved out} and emit errors on access, such as in this code:
\begin{minted}{rust}
let tuple: (Vec<u32>, Vec<u32>) = (vec![], vec![]);
drop(tuple.0); // moved out of `tuple`
println!("{:?}", tuple.0); // ERROR
\end{minted}

All the necessary input facts are already collected but the actual
implementation and testing of the logic depends on a re-designed interface
between the Rust compiler and Polonius, which would have required extensive
interaction with the rest of the compiler team. However, the lion's part of the
work is in place.

\subsection{Illegal Subset Relations}
\label{sec:missing-features:illegal-subset-relations}

Polonius currently does not verify that a subset relationship it finds between
provenance variables is actually valid in itself. For example, this unsound code
would not generate an error in today's Polonius:
\begin{minted}{rust}
fn pick_one<'x, 'y>(x: &'x [u32], y: &'y [u32]) -> &'x u32 {
    &y[0]
}
\end{minted}

In this case, \InRust{pick_one()} takes two slices with some unknown provenance
variables at least known to live for the duration of the function body. The
subtyping rules would give that \InRust{'y} $\subseteq$ \InRust{'x} at the end
of the function, because the reference into \InRust{y} must be a subtype of
\InRust{&'x u32}, the return type. However, this cannot be guaranteed to hold in
general, as Polonius (currently) knows nothing about the relationship between
these two provenance variables, and in fact, as \InRust{pick_one()} is
polymorphic over these provenance variables, this must hold for \emph{any} pair
of provenance variables \InRust{'x, 'y}, which it certainly does
not~\cite{matsakis_polonius_2019-1}.

\subsection{Analysis of Higher Kinds}
\label{sec:missing-features:higher-kinds}

The final missing functionality in Polonius is interaction with higher-ranked
(generic, etc) subtyping arising from generic functions or trait-matching. The
problem was described in a blog entry by \citeauthor*{matsakis_polonius_2019} and
will require extensions in the Rust compiler, which would produce simpler
constraints than the universally and existentially quantified constraints
generated by the type checker for Polonius to
solve~\cite{matsakis_polonius_2019}. The current plan is to use the already
existing infrastructure in Rust for this, but at the time of writing work on
this has not even reached the planning stage.

\subsection{Addressing a Provenance Variable Imprecision Bug}
\label{sec:missing-features:provenance-variable-equality}

During the work for this thesis, a shortcoming in both Polonius and (probably)
\citeauthor*{weiss_oxide:_2019}'s Oxide, discussed in
Section~\ref{sec:type-system} was discovered, which would generate spurious
errors in examples like Listing~\ref{lst:polonius-reformulation-bug} where an
imprecision in the tracking of subset relations would cause a loan to be
propagated to a provenance variable erroneously, leading to effectively dead
loans being considered live. Correcting this problem would require modifications
to how the propagation of subset relations across the CFG~works, which would not
concern the liveness or initialisation tracking implemented as part of this
thesis, but would affect the solution described in
Section~\ref{sec:loan-constr-prop}. At the conclusion of the work for this
thesis, the Polonius working group had not yet produced a final reformulation of
Polonius that would address this issue.

\begin{sourcecode}
  \captionof{listing}{An example where the current Polonius loses precision and
    emits a spurious error, as it conflates the provenance variables \InRust{'x}
    and \InRust{'y}.}\label{lst:polonius-reformulation-bug}
\begin{minted}{rust}
let mut z: u32;
let mut x: &'x u32;
let mut y: &'y u32;

if something {
  y = x; // creates `'x subset-of 'y`.
}

if something {
  x = &z; // creates {L0} in 'x constraint.
          //
          // at this point, we have 
          //   `'x subset-of 'y` and `{L0} in `'x`,
          //   so we also have `{L0} in 'y` (wrong).
  drop(x);
}

z += 1; // Polonius: false positive error

drop(y);
\end{minted}
\end{sourcecode}


\section{Generating Facts for Polonius in the Rust Compiler}

As stated above, the Polonius analysis is performed on the MIR, and the results
are then mapped back onto the source code when generating user-facing errors.
While Polonius is a self-contained package with a well-defined interface,
however, the interface to the code performing the translation of
compiler-internal data structures into input facts for Polonius has a much
larger surface area. All the additions to the Rust compiler occurs in the
\texttt{librustc\_mir::borrow\_check::nll}~module, that is alongside the current
borrow checker (``NLL''). The module hierarchy and the location of emission of
the various facts is shown in Figure~\ref{fig:fact-module-hierarchy}. It is
worth noting that the Polonius analysis piggy-backs off of previous analysises,
notably the \texttt{outlives} constraints generated by the previous borrow
checker during type-checking.

All facts except \texttt{invalidates}, \texttt{cfg\_edge}, \texttt{killed},
\texttt{borrow\_region}, \texttt{outlives}, and \texttt{universal\_region} were
added as part of the work on this thesis.

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/rustc-module-structure}
  \caption[Polonius In Rust's Module Hierarchy]{An illustration of where in the
    module hierarchy of the Rust compiler the various facts are emitted.
    Underscores are replaced with white space for readability. Blue boxes
    represent facts, and black boxes (sub-)modules.}
  \label{fig:fact-module-hierarchy}
\end{figure}

All inputs based on provenance variables (that is, the ones with ``region'' in
their names from the previous terminology); \texttt{path\_belongs\_to\_var},
\texttt{universal\_region}, \texttt{borrow\_region}, \texttt{var\_uses\_region},
and \texttt{outlives}, are all generated using information obtained during
MIR~type-checking. The rest of the inputs are generated either from walking the
MIR directly (\texttt{invalidates}, \texttt{cfg\_edge}, and all the facts
concerning variable uses and drops), or from intermediary indices generated from
the MIR in earlier parts of the compilation process (all facts related to move
paths, which are identified by previous compilation steps). All of this suggests
that the design shown in Figure~\ref{fig:fact-module-hierarchy} should be
refactored to reflect these data dependencies, unifying the generation of most
facts into a common Polonius module higher up in the hierarchy, and leaving only
the ones needing the transient and internal output from the type checker (i.e
provenance variables and their relations to each other and to variables) under
the \texttt{type\_check} submodule. This possible future design is discussed in
more detail in Chapter~\ref{cha:conclusions}.

Returning to one of the examples of the borrowing rules in
Section~\ref{sec:borrowing-rules}, we can describe some of the facts that would
be output on each line. An annotated example can be seen in
Listing~\ref{lst:polonius-fact-emission}.

\begin{sourcecode}
  \captionof{listing}{A minimal example of a violated loan in Rust and the
    Polonius input facts it would produce during
    compilation.}\label{lst:polonius-fact-emission}
\begin{minted}{rust}
    let mut pt = Point(6, 9); // var_defined(pt)
    let x = &mut pt;  // var_defined(x),
                      // var_used(pt),
                      // borrow_region('1, b0)
                      // outlives('1, 'x)
                      // var_uses_region(x, 'x)
    let y = &mut pt;  // invalidates(b0)
                      // ...

   // we assume var_used(x), var_used(y) is emitted here.
\end{minted}
\end{sourcecode}

In practice, this would happen at the MIR level, which would introduce
intermediary variables. However, the core reasoning is the same: the right-hand
side of the assignment is typed with a provenance variable \InRust{'1},
containing only that loan. The assignment to \InRust{x} then sets up a subtyping
relationship with the corresponding \InDatalog{outlives('1, 'x)} fact that
propagates it to \InRust{x}'s provenance variable \InRust{'x}, ensuring it is
considered live when the loan on the next line generates a fact
\InRust{invalidates(b0)}, resulting in the eventual derivation of an
\InRust{error}.

\section{A Field Study of Polonius Inputs}\label{sec:field-study-borrow}

We selected for analysis roughly 20 000~publicly available Rust packages
(``crates'') from the most popular projects as defined by number of downloads
from Crates.io and number of stars on GitHub.~\footnote{Source code for the
  analysis as well as listings of the repositories are available at
  \url{https://github.com/albins/msc-polonius-fact-study}.} Of the initially
selected repositories only about 1 000 were from other sources than GitHub. Only
crates that compiled under recent versions of Rust nightly builds with
non-linear lifetimes enabled were kept. This was due to the difficulty of
isolating compilation errors due to missing dependencies on external C libraries
or syntactically invalid code, both of which would happen long before Polonius
in the compilation process, from errors that would involve Polonius. The source
code of the packages was then translated to Polonius input files for a total of
340~GBs~of tuples for 3~939~171~Rust functions (user-written as well as
compiler-generated), which we used to measure Polonius runtime performance as
well as for finding common patterns in the input data. Only complete data sets
were considered; a repository with more than one target where at least one
target did not compile was discarded, as was any repository where the analysis
of input facts took more than 30~minutes, required more memory than what was
available, or where the initial fact generation phase took longer than
30~minutes. After this selection process, 12~036~repositories remained for the
final study, each of which contained at least one, but possibly multiple crates.
The analysis assumed that all functions in all crates and all targets of a
repository were unique, as the outputs were stored per-repository. The median
number of functions in the dataset was 48, including functions generated by
desugaring as well as user-written functions.

All experiments were run on a dedicated desktop computer running a 64-bit
version of Ubuntu~19.04 with Linux 5.0.0-20-generic. The machine had 16~GBs of
2666~MHz CL16 DDR4~RAM, and a AMD Ryzen~5 2600 CPU running at a base clock of
3.4~GHz (max boost clock 3.9~GHz) with cache sizes of 576~KB (L1), 3~MB (L2),
and 16~MB (L3). Executing the full set of jobs took around two weeks.

Additionally, we also excluded all functions that had no loans at all from the
analysis, a surprisingly large portion; slightly above 64\%. This is most likely
due to code generation producing short ``functions'' that does not actually
involve any borrowing at all. After discarding these, 11~687 repositories
remained.

The main metric of ``performance'' in this study is the time it would take
Polonius to solve a given set of inputs from a cold start. This also includes
the time it takes to parse the files of tab-separated input tuples,
initialisation, liveness, and the borrow check. In practical scenarios the peak
memory usage of the analysis would also be an interesting metric. Additionally,
a future benchmarking scenario should use Polonius to benchmark itself rather
than an external wall-clock, allowing for more precise measurements excluding
parsing and deserialisation and reporting separate runtimes for the three
phases of the calculation.

When studying inputs to Polonius, we are mainly interested in two properties;
how large and how complex the function under analysis is. Neither of these can
be measured directly, but potentially useful proxy variables would be sizes of
input tuples, the number of variables, loans, and provenance variables, as well
as common and cheaply computed graph complexity metrics such as the node count,
density, transitivity, and number of connected components of the control-flow
graph.

Three variants of Polonius were included in the study; a \textsc{Naive}
implementation, which is the one described in
Section~\ref{sec:borr-check-datal}, an optimised variant
(\textsc{DatafrogOpt}~\notmine{}), and a variant that first executes a simpler
analysis assuming lexical lifetimes and falls back to the full Polonius analysis
only when that one produces an error (\textsc{Hybrid}). The intention is to have
such a hybrid algorithm re-use the information gained by the simpler analysis to
accelerate the more advanced analysis, but such functionality was not yet
implemented at the time of the experiments. This mode also performs the full
liveness and initialisation analysis twice, penalising it in the
comparison.

The box plots in Figures~\ref{fig:solvetimes},~\ref{fig:solvetimes-long},
and~\ref{fig:input-sizes} are all Tukey plots; the green line shows the median,
the box the 1 and 3rd quartile, and the whiskers are placed at 1.5~times the
interquartile range. Outliers are not plotted, as the size of the input resulted
in too many outliers for the plots to be readable.

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/solvetimes_boxplot.pdf}
  \caption[Runtimes Per Function for Three Polonius Variants]{A box plot
    showing the distribution of runtimes per function for three
    implementations of Polonius. As can be seen here, the vast majority execute
    very quickly.}
  \label{fig:solvetimes}
\end{figure}


\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/solvetimes_boxplot_over_1s.pdf}
  \caption[Runtimes Per Function for Two Polonius Variants on Longer-Running Inputs]{A box plot showing the distribution of runtimes per function for
    the two optimised Polonius implementations on just functions that executed
    in between 1--50s on \textsc{Naive}.}
  \label{fig:solvetimes-long}
\end{figure}

\subsection{Performance}\label{sec:inputs:performance}

In general, all three algorithms finished quickly for almost all functions, with
both of the optimised algorithms already showing improvements in runtimes, as
seen in Figure~\ref{fig:solvetimes}. Apparently, \textsc{Naive} has a wider
spread of runtimes than the others. Additionally, geometric means of the
observed runtimes show improvements from hybridisation
(Figure~\ref{fig:solvetimes-gmean-repo}), though it should be noted that the
algorithm's worst-case of an input that fails both the simple and the full
analysis was left out of the sample as that would have failed compilation,
possibly inflating the results artificially. We can also see clearly that
\textsc{Hybrid} outperforms its fallback flow-sensitive \textsc{DatafrogOpt}
implementation even when excluding smaller inputs~\ref{fig:solvetimes-long}.

\begin{figure}
  \includegraphics[width=0.5\linewidth]{Graphs/solvetimes_repo_gmean.pdf}
  \caption[Geometric Means of Runtimes Per Repository]{Geometric means of the
    runtimes per repositoriy and implementation.}
  \label{fig:solvetimes-gmean-repo}
\end{figure}


\subsection{What is a Typical Input?}\label{sec:inputs:inputs}

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/input_sizes_boxplot.pdf}
  \caption[Distribution of Polonius Input Tuple Sizes]{A box plot showing the
    distribution of the various input sizes.}
  \label{fig:input-sizes}
\end{figure}

\begin{figure}
  \includegraphics[width=0.5\linewidth]{Graphs/var_drop_used_size_dist.pdf}
  \caption[Distribution of Input Sizes for the \InDatalog{var_drop_used} Fact]{A
    plot showing the distribution of \InDatalog{var_drop_used}.}
  \label{fig:input-var-drop-used}
\end{figure}

A typical Polonius input consists of a small number of tuples for most
relations, as seen in Figure~\ref{fig:input-sizes}. In particular, most
control-flow graphs are small in terms of number of nodes, and most functions
only contain a small number of variables, with an even smaller number of loans.
Drops are particularly rare, with circa~70\% of all studied functions having
no (potential) drop-uses at all (0 median, 7.6 mean), and only very few
loans (2~median, 5~mean). This can also be seen in
Figure~\ref{fig:input-var-drop-used} showing the distribution of number of
(potential) drop-uses per function. In practice, this means that users generally
do not override the built-in deallocators, do not explicitly deallocate their
variables. The low number of loans also means that functions in general do not
use complicated reference-sharing, typically only manipulating a few references.

This points towards a need to have a low starting overhead for Polonius, as
much of its analysis would have to be performed on very small inputs, where the
runtime would be dominated by a high constant setup time.

However, repositories can be assumed to be typically compiled all at once.
Therefore, it is also interesting to say something about the maximum input size
per repository, under the assumption that few large functions would dominate the
runtime for that repository. After collecting the maximum values per repository,
the median number of loans was~24, and the median number of potential drop-uses
was~45 (regular uses was, for comparison, 177).

We attempted to perform a principal-component analysis (PCA) of the input data
in order to visually identify possible clusterings of types of inputs, but the
results were unusable as the inputs had no visually discernible patterns in
neither 2 nor 3 dimensions, suggesting that most inputs are in some sense
typical, or that PCA is ineffective here.

\subsection{How Inputs Affect Runtime}\label{sec:inputs:correlation}
\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/corr_heatmap.pdf}
  \caption[Heatmap of Input Sizes Affecting Runtime]{Heatmap of
    Pearson~correlations between various input size metrics and runtimes for
    all three Polonius implementations, suggesting in particular that variable
    uses, number of variables, and the number of provenance variables heavily
    affect runtime.}
  \label{fig:corr-heatmap}
\end{figure}
A heatmap of the (Pearson) correlation between input size and runtime for the
various variants on long-running jobs (as previously defined to be jobs taking
at least 1s and no more than 50s to run under \textsc{Naive}) can be seen in
Figure~\ref{fig:corr-heatmap} and Table~\ref{tab:correlations}, while a scatter
plot of the results with a linear regression for some interesting pairs of
inputs can be seen in Figure~\ref{fig:input-scatter}.

\begin{table}[ht]
  \input{correlations.tex}
  \caption[Pearson Correlations Between Sizes of Inputs and Runtime]{Pearson
    correlations between size of inputs and the runtime of \textsc{Naive},
    \textsc{Hybrid}, and \textsc{DatafrogOpt} respectively, from high
    correlation to \textsc{DatafrogOpt} runtime to low.}
  \label{tab:correlations}
\end{table}%

It is clear here that inputs affecting all parts of the computation have a
larger influence, notably variable uses, number of variables, and the number of
provenance variables. In particular, input sizes affecting the liveness
computation time affects \textsc{Hybrid}, which should be no surprise as it does
that computation twice. The same goes for the number of provenance variables,
which figure in the second two parts of the analysis. Another conclusion from
Table~\ref{tab:correlations} is that the number of nodes of the CFG has a lower
impact on runtime than its number of edges, reflecting that complex CFGs with
many branchings take more time to compute than linear ones.

Both results suggest only a weak linear relation between input sizes and
and the runtime with \textsc{Naive}, while a clearer relation can be
found between \textsc{DatafrogOpt} and input sizes respectively. \textsc{Naive},
on the other hand, does not show similarly clear correlations between runtime
and input sizes of any kind (Table~\ref{tab:correlations}).

\begin{figure}
  \includegraphics[width=0.9\linewidth]{Graphs/corr_scatter.pdf}
  \caption[Scatter Plot of Runtimes On Two Polonius Variants vs. nr. of CFG
  Edges and Variables]{Scatter plot of runtimes under the naive and optimised
    algorithms compared to variables and CFG edge count after having pruned
    extreme values (runtimes below 1~s or above 13~minutes). Y~axis is runtime
    in seconds.}
  \label{fig:input-scatter}
\end{figure}


\section{Optimising the Borrow Checker}\label{sec:optim-borr-check}

Before Polonius can replace NLL as the Rust borrow checker, it would need
considerable performance improvements in both its fact generation process as
well as the solving itself. In its current condition, the fact generation code,
in particular, performs multiple walks across the CFG, needlessly increasing
runtime. Additionally, many of the inputs are computed unnecessarily, and, for
example, the CFG could be compressed for some cases.

Returning to the analysis of Section~\ref{sec:field-study-borrow}, we can see
from the performance of even the current naive \textsc{Hybrid} implementation,
which first performs a non-flow sensitive analysis and then falls back to the
full Polonius analysis, outperforms both the optimised analysis alone and
\textsc{Naive}. We can also see that inputs without any loans at all are common,
and in those cases the analysis can typically terminate before performing any
analysis at all. Finally, \textsc{Naive} could be improved in two ways. First,
in the current implementation initialisation and liveness analysis is performed
twice for purely architectural reasons. A better implementation would calculate
them once and re-use the results. Second, the current analysis does not use the
errors from the flow-insensitive analysis when it falls back to the full
flow-sensitive Polonius. Recycling the errors from the first analysis could in
many cases reduce the search space for Polonius significantly, as any other
error has already been ruled out in the simpler analysis.

Finally, Datafrog itself could be optimised, including using faster vector
instructions or parallelisation techniques. Additionally, several of the input
relations used in Polonius are only used to exclude values, and never used to
propagate them. This suggests it would be possible to use more compact data
structures for representing them, such as Bloom filters.

\chapter{Conclusions and Future Work}\label{cha:conclusions}

In this report, we have described a first implementation of the Rust borrow
check in Datalog. We have shown how partial initialisation tracking was used
along with variable-use and definition data to determine live references, which
were then used to detect which potential loan violations happening in the code
would actually be of a live reference, therefore causing an error.

Building on top of this, we then analysed Rust code from  ca~12~000 popular Git
repositories to determine what a characteristic Polonius input would look like.
The study found that relatively few functions use any references at all,
suggesting that the borrow check should be able to terminate early in a
significant number of cases. On the same note, we also found that foregoing the
full flow-sensitive analysis and falling back on a simpler analysis, even
naively, in many cases improves performance significantly. Finally, the study
concluded that the number of transitions in the control-flow graph and the
number of variables both would be good proxies for the difficulty of solving an
input in Polonius, in terms of run-time.

Left to do in Polonius before it is feature-complete is integrating it with the
Rust type checker for higher-order kinds, finishing the full initialisation
tracking, and extending the analysis to also include illegal subset constraints
on reference type provenance variables. Finally, we also briefly discussed a
recently discovered shortcoming believed to exist in both Polonius and the Oxide
formulation~\cite{weiss_oxide:_2019}, related to provenance variable imprecision
in the analysis causing spurious errors. This issue is currently under
investigation, and addressing it would likely impact the performance of
Polonius, though possibly in a positive direction as a less precise formulation
would potentially (in some cases) produce fewer tuples to propagate during
analysis.

\begin{figure}
  \includegraphics[width=\linewidth]{Graphs/polonius-refactor}
  \caption[Suggested Refactoring for the Polonius Fact Generation in Rust]{A
    suggestion for how the Polonius fact generation in Rust can be reorganised.
    Green boxes show inputs, black boxes Rust modules, and red modules (re)moved
    components. Note that boxes are grouped together according to the inputs
    necessary for producing them.}
  \label{fig:fact-refactor}
\end{figure}

Finally, there is a need to refactor both Polonius itself (whose interface is
outside the scope of this thesis), and the fact generation code of
Figure~\ref{fig:fact-module-hierarchy}. Such a refactoring could even reduce the
number of iterations over the MIR during input generation, decreasing the
runtime of that part of the code. A proposal for how the fact-generation code
could be reorganised is shown in Figure~\ref{fig:fact-refactor}. The key idea is
to divide the fact generation code according to where in the compilation process
it takes is inputs, such that only the parts needing access to the internal
parts of the type-checker are executed during type-checking. This grouping of
code according to the data it operates on also means that costly operations,
notably CFG iteration, can be performed all at once.

\Urlmuskip=0mu plus 15mu\relax
%\backmatter
\printbibliography[heading=bibintoc]
\end{document}